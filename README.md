# ChurnInsight API ðŸŽµ

API de Machine Learning para prediÃ§Ã£o de churn de usuÃ¡rios em plataformas de streaming de mÃºsica, desenvolvida com Spring Boot e ONNX Runtime.

> ðŸ† Projeto desenvolvido pela **Equipe DataBeats** para o **Hackathon ONE (Oracle Next Education)**

## ðŸ“‹ Sobre o Projeto

ChurnInsight Ã© uma aplicaÃ§Ã£o que utiliza um modelo de Logistic Regression treinado com tÃ©cnica SMOTE para prever a probabilidade de cancelamento (churn) de assinantes de serviÃ§os de mÃºsica. A API recebe dados comportamentais do usuÃ¡rio e retorna a probabilidade de churn em tempo real.

### CaracterÃ­sticas Principais

- âœ… **InferÃªncia em tempo real** usando ONNX Runtime
- âœ… **DiagnÃ³stico com IA** - AnÃ¡lise de fatores de risco e retenÃ§Ã£o
- âœ… **Processamento em Lote** - AtÃ© 1 milhÃ£o de registros (CSV/XLSX) com status em tempo real
- âœ… **HistÃ³rico de PrediÃ§Ãµes** - Busca paginada com 15+ filtros avanÃ§ados
- âœ… **PrediÃ§Ãµes PrÃ©-Calculadas** - Carregamento rÃ¡pido de clientes do `clients.json`
- âœ… **Arquitetura Hexagonal** (Ports & Adapters) - Desacoplamento total
- âœ… **Cache em 2 camadas** - HTTP + Caffeine (memÃ³ria)
- âœ… **Rate Limiting** por IP/usuÃ¡rio com bucket4j
- âœ… **MÃ©tricas** via Actuator/Prometheus (custom metrics)
- âœ… **Health Check** personalizado para modelo ONNX
- âœ… **SeguranÃ§a** com Spring Security (HTTP Basic + CORS)
- âœ… **ContainerizaÃ§Ã£o** com Docker & Docker Compose
- âœ… **MigraÃ§Ãµes automÃ¡ticas** com Flyway
- âœ… **Processamento paralelo** - ThreadPool otimizado para 10K req/s

---

## ðŸ—ï¸ Arquitetura

O projeto segue os princÃ­pios da **Arquitetura Hexagonal**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CAMADA DE ENTRADA                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ REST Controller â”‚          â”‚  Rate Limiter    â”‚          â”‚
â”‚  â”‚   /predict      â”‚  â”€â”€â”€â”€â”€â”€â–º â”‚   Filter         â”‚          â”‚
â”‚  â”‚   /stats        â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CAMADA DE APLICAÃ‡ÃƒO                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚       ChurnPredictionService (Use Cases)             â”‚   â”‚
â”‚  â”‚  â€¢ PredictChurnUseCase                               â”‚   â”‚
â”‚  â”‚  â€¢ PredictionStatsUseCase                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CAMADA DE DOMÃNIO                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ CustomerProfile  â”‚    â”‚  ChurnStatus (Enum) â”‚            â”‚
â”‚  â”‚  (Value Object)  â”‚    â”‚  â€¢ WILL_CHURN       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â€¢ WILL_STAY        â”‚            â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CAMADA DE INFRAESTRUTURA                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ OnnxRuntimeAdapterâ”‚           â”‚ MySQLHistoryAdapter â”‚    â”‚
â”‚  â”‚  (InferÃªncia ML)  â”‚           â”‚  (PersistÃªncia)     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Novas Features (v2.0)

### ðŸŽ¯ DiagnÃ³stico de IA com AnÃ¡lise de Fatores

Cada prediÃ§Ã£o agora retorna uma anÃ¡lise detalhada com:

```json
{
  "diagnosis": {
    "risk_factors": [
      "Alta taxa de skip (15%)",
      "Poucas anÃºncios escutados (0/semana)",
      "Idade jovem (correlaÃ§Ã£o com churn)"
    ],
    "retention_factors": [
      "Tempo de escuta saudÃ¡vel (540min/dia)",
      "Assinatura Premium (maior lealdade)"
    ],
    "recommendation": "OfereÃ§a recomendaÃ§Ãµes personalizadas e reduza frequÃªncia de anÃºncios"
  }
}
```

### ðŸ“¦ Processamento em Lote Ultra-Otimizado

- **Velocidade:** 10.000 registros/segundo (100K em 10s)
- **Suporte:** CSV e XLSX com atÃ© 1 milhÃ£o de registros
- **Tamanho:** AtÃ© 200MB por arquivo
- **Status em Tempo Real:** Acompanhe progresso do processamento
- **PersistÃªncia em Batch:** Multi-row INSERT com pool de threads
- **RecuperaÃ§Ã£o:** Jobs persistidos em banco para retomar apÃ³s reinÃ­cio

**Exemplo de uso:**

```bash
curl -X POST http://localhost:10808/predict/batch \
  -u admin:Admin123 \
  -F "file=@clientes.csv"

# Retorna job_id para acompanhar progresso
# GET /predict/batch/status/{job_id}
```

### ðŸ” Busca AvanÃ§ada com 15+ Filtros

HistÃ³rico de prediÃ§Ãµes com suporte a:

- Filtros por perÃ­odo (startDate, endDate)
- Filtros por probabilidade (minProbability, maxProbability)
- Filtros por status de churn (WILL_CHURN, WILL_STAY)
- Filtros demogrÃ¡ficos (age, gender, country)
- OrdenaÃ§Ã£o flexÃ­vel (createdAt, probability, age, etc)
- PaginaÃ§Ã£o (atÃ© 100 registros por pÃ¡gina)

**Exemplo:**
```
GET /clients?page=0&size=50&sortBy=probability&churnStatus=WILL_CHURN&ageMin=20&ageMax=35&country=Brazil
```

### ðŸ“Š PrediÃ§Ãµes PrÃ©-Calculadas de Clientes

Carregamento rÃ¡pido de prediÃ§Ãµes prÃ©-calculadas do `clients.json`:

- Cache em memÃ³ria para O(1) lookup por clientId
- Ãndices para busca eficiente
- EstatÃ­sticas agregadas

### ðŸ“‹ Contrato da API (Schema)

Endpoint `/api/contract` retorna esquema completo com:

- ValidaÃ§Ãµes esperadas
- Tipos e ranges de cada field
- VersÃ£o do modelo
- Compatibilidade de schema

### ðŸ§¬ Regras de NegÃ³cio Centralizadas

Classe `ChurnBusinessRules` com toda a lÃ³gica centralizada:

```java
public static boolean isChurning(double probability) {
    return probability > CHURN_THRESHOLD; // 0.412
}
```

---

## ðŸš€ Tecnologias

### Core
- **Java 21** (Eclipse Temurin)
- **Spring Boot 3.5.9**
- **Spring Security** (HTTP Basic Auth)
- **Spring Data JPA** + Hibernate
- **Spring Validation** (Jakarta Validation)

### Machine Learning
- **ONNX Runtime 1.19.2** (inferÃªncia do modelo)
- **Logistic Regression com SMOTE** (modelo treinado)

### Banco de Dados
- **MySQL 8.0** (mysql-connector-j)
- **Flyway** (migraÃ§Ãµes de schema)

### Cache & Performance
- **Caffeine Cache 3.1.8** (cache em memÃ³ria)
- **Bucket4j 8.14.0** (rate limiting)

### Observabilidade
- **Spring Boot Actuator**
- **Micrometer** + **Prometheus Registry**
- **Custom Health Indicators**

### Processamento em Lote
- **Apache POI 5.2.4** (leitura de XLSX)
- **xlsx-streamer 2.1.0** (streaming para grandes arquivos XLSX)
- **Univocity Parsers 2.9.1** (parsing de CSV otimizado)

### Observabilidade
- **Spring Boot Actuator**
- **Micrometer** + **Prometheus Registry**
- **Custom Health Indicators** (modelo ONNX)
- **SpringDoc OpenAPI 2.8.15** (Swagger/OpenAPI 3.0)

### UtilitÃ¡rios
- **Lombok** (reduÃ§Ã£o de boilerplate)
- **dotenv-java 3.2.0** (gerenciamento de variÃ¡veis de ambiente)
- **Log4j** (logging estruturado via SLF4J)

### ContainerizaÃ§Ã£o
- **Docker** + **Docker Compose**
- **Multi-stage build** para otimizaÃ§Ã£o de imagem
- **ZGC Garbage Collector** para baixa latÃªncia

---

## ðŸ§¬ Internals - Como Funciona

### Pipeline de Batch Processing

O processamento em lote segue um pipeline otimizado:

```
Upload do Arquivo
    â†“
[ValidaÃ§Ã£o] - Verifica formato, tamanho e headers
    â†“
[Parsing AssÃ­ncrono] - LÃª arquivo em chunks (2.500 registros)
    â†“
[Enriquecimento] - Mapeia CSV para CustomerProfile
    â†“
[InferÃªncia Paralela] - 10 threads executam modelo ONNX (10K/s)
    â†“
[PersistÃªncia em Batch] - Multi-row INSERT com JDBC (1.500/chunk)
    â†“
[Job Status Update] - Atualiza progresso em real-time
    â†“
Processamento Completo
```

**OtimizaÃ§Ãµes aplicadas:**

1. **Streaming:** LÃª arquivo em chunks, nÃ£o carrega tudo em memÃ³ria
2. **Parsing Paralelo:** Univocity para CSV (mais rÃ¡pido que Jackson)
3. **InferÃªncia Paralela:** ThreadPool de 10 threads para ONNX
4. **Batch Inserts:** Multi-row INSERT com rewriteBatchedStatements
5. **JDBC direto:** Bypassa Hibernate ORM para inserts em massa
6. **Cache Manager:** Limpa cache automÃ¡tico apÃ³s batch grande

### Cache em 2 Camadas

1. **HTTP Cache (Spring):** Decoradores `@Cacheable` em controllers
   - TTL: 30 minutos
   - Max size: 50.000 prediÃ§Ãµes

2. **Caffeine Cache (MemÃ³ria):** Cache local ultra-rÃ¡pida
   - Lookup O(1) para prediÃ§Ãµes repetidas
   - Eviction automÃ¡tica apÃ³s TTL

### Arquitetura Hexagonal (Ports & Adapters)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      REST Controller (Input)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Use Case Interface (Application)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Domain Model & Business Rules      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Inference    â”‚  â”‚ Database         â”‚
â”‚ Port (ONNX)  â”‚  â”‚ Port (MySQL)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Rate Limiting com Bucket4j

Implementa algoritmo **Token Bucket**:

- 50 requisiÃ§Ãµes/segundo por IP/usuÃ¡rio
- Burst capacity: 100 requisiÃ§Ãµes
- Resposta 429 quando limite excedido
- Headers informativos (X-Rate-Limit-*)

### UUIDv7 para IDs

Cada prediÃ§Ã£o recebe um ID Ãºnico UUIDv7:

```java
String predictionId = UUIDv7.randomUUID().toString();
// Garante: sortable por timestamp + aleatÃ³rio
// Melhor para Ã­ndices em banco de dados
```

---

O modelo ONNX foi treinado com as seguintes caracterÃ­sticas:

| MÃ©trica | Valor |
|---------|-------|
| Accuracy | 51.44% |
| Precision | 26.76% |
| Recall | 50.48% |
| F1-Score | 34.98% |
| AUC-ROC | 50.05% |
| Threshold Ã“timo | 0.412 |

**Features NumÃ©ricas:**
- `age`, `listening_time`, `songs_played_per_day`, `skip_rate`, `ads_listened_per_week`, `offline_listening`

**Features CategÃ³ricas:**
- `gender`, `country`, `subscription_type`, `device_type`

---

## âš™ï¸ ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos

- Docker & Docker Compose instalados
- Porta `10808` (API) e `3306` (MySQL) disponÃ­veis

### 1. Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:

```env
# Database
DB_NAME=churn_db
DB_ROOT_PASSWORD=seu_password_root_aqui
DB_USER=churn_user
DB_PASSWORD=seu_password_user_aqui
DB_URL=jdbc:mysql://localhost:3306/churn_db

# Security
SECURITY_USER=admin
SECURITY_PASSWORD=seu_password_seguro_aqui
SECURITY_ROLES=ADMIN
```

> âš ï¸ **IMPORTANTE:** Nunca commite o arquivo `.env` no repositÃ³rio! Ele jÃ¡ estÃ¡ no `.gitignore`.

### 2. Executar com Docker Compose

```bash
# Build e start dos containers
docker-compose up --build

# Ou em modo detached (background)
docker-compose up -d --build
```

A API estarÃ¡ disponÃ­vel em: `http://localhost:10808`

### 3. Verificar Health Check

```bash
curl http://localhost:10808/actuator/health
```

Resposta esperada:
```json
{
  "status": "UP",
  "components": {
    "db": {
      "status": "UP",
      "details": {
        "database": "MySQL",
        "validationQuery": "isValid()"
      }
    },
    "diskSpace": {
      "status": "UP",
      "details": {
        "total": 983347249152,
        "free": 849019969536,
        "threshold": 10485760,
        "path": "/app/.",
        "exists": true
      }
    },
    "model": {
      "status": "UP",
      "details": {
        "status": "Modelo ONNX carregado com sucesso",
        "session": "Ativa"
      }
    },
    "ping": {
      "status": "UP"
    },
    "ssl": {
      "status": "UP",
      "details": {
        "validChains": [],
        "invalidChains": []
      }
    }
  }
}
```

---

## ðŸ“¡ Endpoints da API

### ðŸ” AutenticaÃ§Ã£o

Todos os endpoints (exceto `/actuator/**`) requerem **HTTP Basic Authentication**.

Adicione o header:
```
Authorization: Basic base64(username:password)
```

### 1. PrediÃ§Ã£o Simples com DiagnÃ³stico

**POST** `/predict`

Realiza uma prediÃ§Ã£o com diagnÃ³stico completo de IA, incluindo fatores de risco e retenÃ§Ã£o.

**Request Body:**
```json
{
  "gender": "Male",
  "age": 29,
  "country": "Brazil",
  "subscriptionType": "Premium",
  "listeningTime": 540.0,
  "songsPlayedPerDay": 12,
  "skipRate": 0.15,
  "adsListenedPerWeek": 0,
  "deviceType": "Mobile",
  "offlineListening": true,
  "userId": "12345"
}
```

**Response:**
```json
{
  "label": "WILL_CHURN",
  "probability": 0.6087930798530579,
  "threshold": 0.412,
  "diagnosis": {
    "risk_factors": ["Alta taxa de skip", "NÃºmero baixo de anÃºncios"],
    "retention_factors": ["Tempo de escuta adequado"],
    "recommendation": "OfereÃ§a recomendaÃ§Ãµes personalizadas e reduza anÃºncios"
  },
  "confidence": 0.95,
  "latency_ms": 25
}
```

### 2. PrediÃ§Ã£o com EstatÃ­sticas Completas

**POST** `/stats`

Retorna prediÃ§Ã£o com probabilidades detalhadas de cada classe e anÃ¡lise do threshold.

**Request Body:** (mesmo formato do `/predict`)

**Response:**
```json
{
  "label": "WILL_CHURN",
  "probability": 0.6087930798530579,
  "probabilities": [0.6087931],
  "classProbabilities": {
    "WILL_CHURN": 0.6087931,
    "WILL_STAY": 0.39120692
  }
}
```

### 3. Processamento em Lote (CSV/XLSX)

**POST** `/predict/batch` (form-data)

Processa mÃºltiplos perfis de clientes de forma assÃ­ncrona. Suporta atÃ© 1 milhÃ£o de registros.

**Request:**
- Form parameter: `file` (CSV ou XLSX)
- Tamanho mÃ¡ximo: 200MB

**Response (202 Accepted):**
```json
{
  "message": "Processamento iniciado com sucesso",
  "job_id": "batch-1234567890",
  "filename": "clientes.csv",
  "size_mb": 45.5,
  "estimated_time_minutes": 23,
  "status_url": "/predict/batch/status/batch-1234567890",
  "timestamp": 1704067200000
}
```

### 4. MÃ©tricas do Dashboard

**GET** `/dashboard/metrics`

**Response:**
```json
{
    "total_customers": 10000,
    "global_churn_rate": 97.5,
    "customers_at_risk": 9750,
    "revenue_at_risk": 150824.0,
    "model_accuracy": 0.5094
}
```

**Monitorar Progresso:**

**GET** `/predict/batch/status/{jobId}`

```json
{
  "job_id": "batch-1234567890",
  "status": "PROCESSING",
  "processed_count": 45000,
  "total_count": 100000,
  "progress_percentage": 45.0,
  "elapsed_time_seconds": 125,
  "estimated_remaining_seconds": 150,
  "error_count": 0,
  "churn_count": 25000,
  "stay_count": 20000
}
```

PossÃ­veis status: `QUEUED`, `PROCESSING`, `COMPLETED`, `FAILED`, `CANCELLED`

### 5. HistÃ³rico de PrediÃ§Ãµes

**GET** `/clients`

Busca paginada com filtros avanÃ§ados de histÃ³rico de prediÃ§Ãµes.

**Query Parameters:**
```
GET /clients?page=0&size=10&sortBy=createdAt&churnStatus=WILL_CHURN&startDate=2024-01-01&endDate=2024-12-31&minProbability=0.5
```

**Response:**
```json
{
  "content": [
    {
      "id": "uuid-predication-id",
      "userId": "12345",
      "gender": "Male",
      "age": 29,
      "country": "Brazil",
      "subscriptionType": "Premium",
      "churnStatus": "WILL_CHURN",
      "probability": 0.6087930798530579,
      "requestIp": "192.168.1.1",
      "createdAt": "2024-01-15T10:30:00Z"
    }
  ],
  "page": 0,
  "size": 10,
  "totalElements": 1500,
  "totalPages": 150
}
```

**Filtros DisponÃ­veis:**
- `page`: PÃ¡gina (0-indexed)
- `size`: Tamanho da pÃ¡gina (max 100)
- `sortBy`: Campo de ordenaÃ§Ã£o (createdAt, probability, age, etc)
- `churnStatus`: WILL_CHURN ou WILL_STAY
- `startDate`: Data inicial (yyyy-MM-dd)
- `endDate`: Data final (yyyy-MM-dd)
- `minProbability`: Probabilidade mÃ­nima
- `maxProbability`: Probabilidade mÃ¡xima
- `ageMin` / `ageMax`: Range de idade
- `country`: Filtrar por paÃ­s
- `gender`: Filtrar por gÃªnero

### 6. PrediÃ§Ãµes PrÃ©-Calculadas de Clientes

**GET** `/clients/predictions`

Retorna lista de prediÃ§Ãµes prÃ©-calculadas carregadas do arquivo `clients.json`.

**Query Parameters:**
- `page`: PÃ¡gina (0-indexed, padrÃ£o: 0)
- `size`: Tamanho da pÃ¡gina (max 100, padrÃ£o: 10)

**Response:**
```json
{
  "content": [
    {
      "clientId": "client-001",
      "churnStatus": "WILL_CHURN",
      "probability": 0.72,
      "features": { /* dados do cliente */ }
    }
  ],
  "page": 0,
  "size": 10,
  "totalElements": 50000
}
```

**GET** `/clients/predictions/search/{clientId}`

Busca prediÃ§Ã£o especÃ­fica de um cliente.

**GET** `/clients/predictions/stats`

EstatÃ­sticas agregadas das prediÃ§Ãµes prÃ©-calculadas.

```json
{
  "totalClients": 50000,
  "churnCount": 18500,
  "stayCount": 31500,
  "churnPercentage": 37.0,
  "avgProbability": 0.485,
  "maxProbability": 0.98,
  "minProbability": 0.05
}
```

### 7. Contrato da API

**GET** `/api/contract`

Retorna o contrato (schema) da API com detalhes de todas as features esperadas.

**Response:**
```json
{
  "version": "1.0",
  "modelVersion": "logistic-regression-v1",
  "features": {
    "numeric": [
      {"name": "age", "type": "integer", "min": 10, "max": 120},
      {"name": "listeningTime", "type": "double", "min": 0}
    ],
    "categorical": [
      {"name": "gender", "type": "string", "values": ["Male", "Female", "Other"]},
      {"name": "country", "type": "string"}
    ]
  }
}
```

### 8. MÃ©tricas e Observabilidade

**GET** `/actuator/metrics`

Retorna mÃ©tricas detalhadas da aplicaÃ§Ã£o.

**GET** `/actuator/prometheus`

Retorna mÃ©tricas no formato Prometheus para integraÃ§Ã£o com Prometheus/Grafana.

**GET** `/actuator/health`

Health check com componentes (Database, Model, Cache, etc)

---

## ðŸ›¡ï¸ SeguranÃ§a

### Rate Limiting

A API implementa rate limiting para evitar abuso:

- **50 requisiÃ§Ãµes/segundo** por IP ou usuÃ¡rio autenticado
- **Burst capacity:** 100 requisiÃ§Ãµes
- Resposta `429 Too Many Requests` quando o limite Ã© excedido

Headers de resposta:
```
X-Rate-Limit-Limit: 100
X-Rate-Limit-Remaining: 87
```

### ValidaÃ§Ãµes

Todos os campos do `CustomerProfile` sÃ£o validados:

| Campo | ValidaÃ§Ã£o |
|-------|-----------|
| `age` | Entre 10 e 120 |
| `listeningTime` | > 0 |
| `songsPlayedPerDay` | >= 0 |
| `skipRate` | Entre 0.0 e 1.0 |
| `adsListenedPerWeek` | >= 0 |
| Campos de texto | NÃ£o podem ser vazios |

---

## ðŸ“¦ Estrutura do Projeto

```
src/main/java/com/hackathon/databeats/churninsight/
â”œâ”€â”€ application/
â”‚   â”œâ”€â”€ dto/                           # Data Transfer Objects
â”‚   â”‚   â”œâ”€â”€ PredictionResult.java      # Resultado de prediÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ ClientPrediction.java      # PrediÃ§Ã£o prÃ©-calculada
â”‚   â”‚   â”œâ”€â”€ BatchProcessingStatus.java # Status do batch
â”‚   â”‚   â””â”€â”€ PaginatedResponse.java     # Resposta paginada
â”‚   â”œâ”€â”€ port/
â”‚   â”‚   â”œâ”€â”€ input/                     # Use Cases (interfaces)
â”‚   â”‚   â”‚   â”œâ”€â”€ PredictChurnUseCase.java
â”‚   â”‚   â”‚   â”œâ”€â”€ BatchProcessingUseCase.java
â”‚   â”‚   â”‚   â”œâ”€â”€ PredictionStatsUseCase.java
â”‚   â”‚   â”‚   â”œâ”€â”€ ClientPredictionQueryUseCase.java
â”‚   â”‚   â”‚   â””â”€â”€ ClientSearchUseCase.java
â”‚   â”‚   â””â”€â”€ output/                    # Ports para adapters
â”‚   â”‚       â”œâ”€â”€ InferencePort.java
â”‚   â”‚       â”œâ”€â”€ SaveHistoryPort.java
â”‚   â”‚       â”œâ”€â”€ BatchSavePort.java
â”‚   â”‚       â””â”€â”€ ModelMetadataPort.java
â”‚   â””â”€â”€ service/                       # ImplementaÃ§Ã£o dos Use Cases
â”‚       â”œâ”€â”€ ApiContractQueryService.java
â”‚       â”œâ”€â”€ ChurnPredictionService.java
â”‚       â”œâ”€â”€ BatchProcessingService.java
â”‚       â”œâ”€â”€ DashboardMetricsService.java
â”‚       â”œâ”€â”€ PredictionHistoryService.java
â”‚       â””â”€â”€ ClientPredictionQueryService.java
â”œâ”€â”€ domain/
â”‚   â”œâ”€â”€ enums/
â”‚   â”‚   â”œâ”€â”€ ChurnStatus.java           # WILL_CHURN, WILL_STAY
â”‚   â”‚   â””â”€â”€ BatchJobStatus.java
â”‚   â”œâ”€â”€ exception/
â”‚   â”‚   â”œâ”€â”€ PredictionException.java
â”‚   â”‚   â””â”€â”€ ModelInferenceException.java
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ CustomerProfile.java       # Value Object
â”‚   â”‚   â”œâ”€â”€ PredictionHistory.java
â”‚   â”‚   â””â”€â”€ BatchJob.java
â”‚   â””â”€â”€ rules/
â”‚       â”œâ”€â”€ ChurnBusinessRules.java
â”‚       â””â”€â”€ ChurnDiagnosisService.java # DiagnÃ³stico de IA
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ adapter/
â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â”‚   â””â”€â”€ web/
â”‚   â”‚   â”‚       â”œâ”€â”€ controller/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ PredictionController.java
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ DashboardController.java
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ ClientQueryController.java
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ ApiContractController.java
â”‚   â”‚   â”‚       â””â”€â”€ dto/
â”‚   â”‚   â”‚           â”œâ”€â”€ CustomerProfileRequest.java
â”‚   â”‚   â”‚           â”œâ”€â”€ PredictionStatsResponse.java
â”‚   â”‚   â”‚           â””â”€â”€ DashboardMetricsResponse.java
â”‚   â”‚   â””â”€â”€ output/
â”‚   â”‚       â”œâ”€â”€ inference/
â”‚   â”‚       â”‚   â””â”€â”€ OnnxRuntimeAdapter.java
â”‚   â”‚       â””â”€â”€ persistence/
â”‚   â”‚           â”œâ”€â”€ MySQLHistoryAdapter.java
â”‚   â”‚           â”œâ”€â”€ JdbcBatchPersistenceAdapter.java
â”‚   â”‚           â””â”€â”€ repository/
â”‚   â”‚               â”œâ”€â”€ PredictionHistoryRepository.java
â”‚   â”‚               â”œâ”€â”€ PredictionHistoryEntity.java
â”‚   â”‚               â””â”€â”€ PredictionHistorySpecification.java
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ BeanConfiguration.java     # ConfiguraÃ§Ã£o de beans
â”‚   â”‚   â”œâ”€â”€ SecurityConfig.java
â”‚   â”‚   â”œâ”€â”€ MetricsConfig.java
â”‚   â”‚   â””â”€â”€ TaskExecutorConfig.java    # Executor para batch
â”‚   â”œâ”€â”€ exception/
â”‚   â”‚   â”œâ”€â”€ GlobalExceptionHandler.java
â”‚   â”‚   â””â”€â”€ ApiErrorResponse.java
â”‚   â”œâ”€â”€ filter/
â”‚   â”‚   â”œâ”€â”€ RateLimitingFilter.java
â”‚   â”‚   â””â”€â”€ CorsConfigurer.java
â”‚   â”œâ”€â”€ health/
â”‚   â”‚   â””â”€â”€ ModelHealthIndicator.java  # Health check customizado
â”‚   â””â”€â”€ util/
â”‚       â”œâ”€â”€ ModelMetadata.java
â”‚       â”œâ”€â”€ NetworkUtils.java
â”‚       â””â”€â”€ UUIDv7.java
â””â”€â”€ ChurnInsightApplication.java

src/main/resources/
â”œâ”€â”€ db/
â”‚   â””â”€â”€ migration/                     # Scripts Flyway
â”‚       â”œâ”€â”€ V1__init_churn_history.sql
â”‚       â”œâ”€â”€ V2__add_engineered_features.sql
â”‚       â””â”€â”€ V3__add_search_indexes.sql
â”œâ”€â”€ clients.json                       # PrediÃ§Ãµes prÃ©-calculadas
â”œâ”€â”€ metadata.json                      # Metadados do modelo
â”œâ”€â”€ contrato_api.json                  # Contrato da API
â”œâ”€â”€ modelo_hackathon.onnx              # Modelo ONNX
â””â”€â”€ application.properties
```

---

## ðŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### Cache (application.properties)

```properties
# Cache HTTP
app.cache.ttl-minutes=30
app.cache.max-size=50000

# Caffeine cache em memÃ³ria para prediÃ§Ãµes repetidas
spring.cache.type=caffeine
spring.cache.caffeine.spec=maximumSize=50000,expireAfterWrite=30m
```

### Processamento em Lote (Batch)

```properties
# ThreadPool para processamento paralelo
app.batch.core-pool-size=6
app.batch.max-pool-size=10
app.batch.size=2500

# Threads dedicadas para inferÃªncia
app.batch.inference-threads=10

# OtimizaÃ§Ã£o de banco de dados
app.db.insert-threads=10
app.db.chunk-size=1500
```

### Rate Limiting

```properties
app.rate-limit.requests-per-second=50
app.rate-limit.burst-capacity=100
```

### File Upload

```properties
# Limite para arquivos de batch processing
spring.servlet.multipart.max-file-size=200MB
spring.servlet.multipart.max-request-size=200MB
```

### JVM Tuning (Dockerfile)

O container estÃ¡ configurado com:
- **ZGC (Z Garbage Collector)** para baixa latÃªncia e pause times < 1ms
- **MaxRAMPercentage=75%** (usa 75% da RAM do container)
- **Virtual Threads (Java 21+)** para melhor throughput

### CORS

```properties
# Origens permitidas
app.cors.allowed-origins=http://localhost:3000,http://127.0.0.1:3000,http://churn-frontend:3000
```

---

## ðŸ“ˆ Monitoramento

### MÃ©tricas Customizadas

- `houseprice.predictions.total` - Total de prediÃ§Ãµes realizadas
- `houseprice.prediction.latency` - LatÃªncia de inferÃªncia (p50, p95, p99)
- `houseprice.requests.active` - RequisiÃ§Ãµes ativas no momento
- `houseprice.errors.total` - Total de erros acumulados

### Health Check Customizado

O endpoint `/actuator/health` verifica mÃºltiplos componentes:

âœ… **Database (MySQL)** - Conectividade e validaÃ§Ã£o do banco  
âœ… **Disk Space** - EspaÃ§o disponÃ­vel no container  
âœ… **Model (ONNX)** - Modelo carregado e sessÃ£o ativa  
âœ… **Ping** - VerificaÃ§Ã£o bÃ¡sica de disponibilidade  
âœ… **SSL** - ValidaÃ§Ã£o de certificados SSL/TLS

Todos os componentes devem estar com `status: "UP"` para a aplicaÃ§Ã£o estar saudÃ¡vel.

---

## ðŸ—„ï¸ Schema do Banco de Dados

### Tabela Churn History (HistÃ³rico de PrediÃ§Ãµes)

```sql
CREATE TABLE churn_history (
    id CHAR(36) PRIMARY KEY COMMENT 'UUIDv7 Ãºnico por prediÃ§Ã£o',
    
    -- Dados de entrada do cliente
    gender VARCHAR(20),
    age INT,
    country VARCHAR(10),
    subscription_type VARCHAR(30),
    listening_time DOUBLE,
    songs_played_per_day INT,
    skip_rate DOUBLE,
    ads_listened_per_week INT,
    device_type VARCHAR(30),
    offline_listening BOOLEAN,
    user_id CHAR(36),
    
    -- SaÃ­da do modelo
    churn_status ENUM('WILL_CHURN', 'WILL_STAY') NOT NULL,
    probability DOUBLE,
    
    -- Auditoria e rastreamento
    requester_id CHAR(36),
    request_ip VARCHAR(45),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Ãndices para performance
    KEY idx_churn_status (churn_status),
    KEY idx_user_id (user_id),
    KEY idx_created_at (created_at),
    KEY idx_probability_desc (probability DESC),
    KEY idx_age_subscription (age, subscription_type),
    KEY idx_country_status (country, churn_status)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### MigraÃ§Ãµes com Flyway

As migraÃ§Ãµes de banco de dados sÃ£o gerenciadas automaticamente via **Flyway**:

**V1__init_churn_history.sql** - CriaÃ§Ã£o da tabela base

**V2__add_engineered_features.sql** - Features derivadas

```sql
ALTER TABLE churn_history ADD COLUMN engagement_score FLOAT
  GENERATED ALWAYS AS (
    (listening_time / 1440.0) * (1 - skip_rate)
  ) STORED COMMENT 'Score de engajamento normalizado';
```

**V3__add_search_indexes.sql** - Ãndices de busca otimizados

```sql
CREATE INDEX idx_probability_desc ON churn_history(probability DESC);
CREATE INDEX idx_age_subscription ON churn_history(age, subscription_type);
CREATE INDEX idx_country_status ON churn_history(country, churn_status);
```

### Performance de Banco de Dados

ConfiguraÃ§Ãµes aplicadas em `application.properties`:

```properties
# Connection Pool (HikariCP)
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=8
spring.datasource.hikari.connection-timeout=30000

# Batch Inserts (otimizado para batch processing)
spring.jpa.properties.hibernate.jdbc.batch_size=1500
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.jdbc.batch_versioned_data=true
spring.jpa.properties.hibernate.jdbc.fetch_size=500

# JDBC rewrite para multi-row inserts (muito mais rÃ¡pido)
spring.datasource.url=...&rewriteBatchedStatements=true&cachePrepStmts=true
```

**Resultado:** Inserts em batch 50-100x mais rÃ¡pidos que individual

---

## ðŸ§ª Testando a API

### Usando cURL

#### 1. PrediÃ§Ã£o Simples

```bash
curl -X POST http://localhost:10808/predict \
  -u admin:Admin123 \
  -H "Content-Type: application/json" \
  -d '{
    "gender": "Male",
    "age": 29,
    "country": "Brazil",
    "subscriptionType": "Premium",
    "listeningTime": 540.0,
    "songsPlayedPerDay": 12,
    "skipRate": 0.15,
    "adsListenedPerWeek": 0,
    "deviceType": "Mobile",
    "offlineListening": true,
    "userId": "12345"
  }'
```

#### 2. Processamento em Lote

```bash
# Iniciar processamento
curl -X POST http://localhost:10808/predict/batch \
  -u admin:Admin123 \
  -F "file=@clientes.csv"

# Exemplo de resposta:
# {
#   "message": "Processamento iniciado com sucesso",
#   "job_id": "batch-1704067200000",
#   "filename": "clientes.csv",
#   "size_mb": 45.5,
#   "estimated_time_minutes": 23,
#   "status_url": "/predict/batch/status/batch-1704067200000"
# }

# Acompanhar progresso (substituir JOB_ID)
curl -u admin:Admin123 \
  http://localhost:10808/predict/batch/status/batch-1704067200000
```

#### 3. Buscar HistÃ³rico com Filtros

```bash
# Buscar prediÃ§Ãµes do Ãºltimos 7 dias com alta probabilidade de churn
curl -u admin:Admin123 \
  "http://localhost:10808/clients?page=0&size=20&sortBy=probability&churnStatus=WILL_CHURN&startDate=2024-01-01&minProbability=0.6"

# Buscar por idade especÃ­fica
curl -u admin:Admin123 \
  "http://localhost:10808/clients?ageMin=20&ageMax=35&country=Brazil"
```

#### 4. EstatÃ­sticas de PrediÃ§Ãµes PrÃ©-Calculadas

```bash
curl -u admin:Admin123 \
  http://localhost:10808/clients/predictions/stats
```

#### 5. Consultar Contrato da API

```bash
curl http://localhost:10808/api/contract
```

#### 6. MÃ©tricas Prometheus

```bash
curl http://localhost:10808/actuator/prometheus
```

### Usando Postman/Insomnia

1. Configure **Authorization â†’ Basic Auth**
2. Username: `admin`
3. Password: `Admin123` (ou valor em `.env`)
4. Body: JSON do CustomerProfile

**Import via Postman:**

VocÃª pode importar a coleÃ§Ã£o OpenAPI diretamente de:
```
http://localhost:10808/v3/api-docs
```

### Criando Arquivo CSV para Batch

**Exemplo de `clientes.csv`:**

```csv
gender,age,country,subscriptionType,listeningTime,songsPlayedPerDay,skipRate,adsListenedPerWeek,deviceType,offlineListening,userId
Male,29,Brazil,Premium,540.0,12,0.15,0,Mobile,true,user-001
Female,35,USA,Free,320.5,8,0.25,5,Desktop,false,user-002
Male,22,Canada,Premium,680.2,15,0.08,0,Mobile,true,user-003
```

**Exemplo de `clientes.xlsx`:**

Crie uma planilha com as mesmas colunas e headers acima, em formato .xlsx

---

## ðŸ› Troubleshooting

### Erro: "Modelo ONNX nÃ£o carregado"

**SoluÃ§Ã£o:** Verifique se o arquivo `modelo_hackathon.onnx` estÃ¡ em `src/main/resources/`

```bash
# Verificar se arquivo existe
ls -la src/main/resources/modelo_hackathon.onnx
```

### Erro: "Connection refused" ao MySQL

**SoluÃ§Ã£o:** Aguarde o health check do MySQL estar pronto:
```bash
docker-compose logs db
# Aguarde atÃ© ver: "ready for connections"

# Ou verificar status:
docker-compose ps
```

### Erro 429 (Too Many Requests)

**SoluÃ§Ã£o:** VocÃª atingiu o rate limit. Aguarde alguns segundos ou aumente o limite em `application.properties`:

```properties
app.rate-limit.requests-per-second=100  # aumentar de 50 para 100
app.rate-limit.burst-capacity=200        # aumentar de 100 para 200
```

### Container da API nÃ£o inicia

**SoluÃ§Ã£o:** Verifique as variÃ¡veis de ambiente e logs:

```bash
docker-compose logs app
```

Erros comuns:
- `.env` nÃ£o configurado
- MySQL nÃ£o iniciou ainda
- Porta 10808 em uso

### Batch Processing lento

**SoluÃ§Ã£o:** Aumentar threads pool em `application.properties`:

```properties
app.batch.max-pool-size=20          # aumentar de 10
app.batch.inference-threads=20       # aumentar de 10
app.db.insert-threads=20             # aumentar de 10
```

Ou aumentar RAM do container (dockerfile):
```dockerfile
ENV JAVA_OPTS="-Xmx2g -XX:+UseZGC"
```

### Erro 400 ao fazer batch: "File size exceeds maximum"

**SoluÃ§Ã£o:** O arquivo Ã© maior que 200MB. Dividir em partes menores:

```bash
# Dividir CSV em arquivos de 100MB
split -b 100M clientes.csv clientes_part_

# Processar cada parte
for file in clientes_part_*; do
  curl -X POST http://localhost:10808/predict/batch \
    -u admin:Admin123 \
    -F "file=@$file"
done
```

### HistÃ³rico vazio apÃ³s prediÃ§Ãµes

**SoluÃ§Ã£o:** Verificar se Flyway rodou as migrations:

```bash
# Ver logs de migration
docker-compose logs app | grep "Flyway"

# Se necessÃ¡rio, resetar e aplicar
docker-compose down -v  # Remove volumes
docker-compose up --build
```

### Cache nÃ£o funcionando

**SoluÃ§Ã£o:** Verificar se Spring Cache estÃ¡ habilitado:

```properties
spring.cache.type=caffeine  # Deve estar presente
```

Limpar cache:
```bash
curl -X POST http://localhost:10808/cache/clear \
  -u admin:Admin123
```

### MÃ©tricas nÃ£o aparecem em Prometheus

**SoluÃ§Ã£o:** Verificar se endpoint estÃ¡ disponÃ­vel:

```bash
curl http://localhost:10808/actuator/prometheus

# Se vazio, verificar se micrometer estÃ¡ habilitado
docker-compose logs app | grep "micrometer"
```

---

## ðŸ‘¥ Equipe DataBeats

### Time Back-End ðŸ’»
- [**Ezandro Bueno**](https://github.com/ezbueno)
- [**Jorge Filipi Dias**](https://github.com/jorgefilipi)
- [**Wanderson Souza**](https://github.com/wandersondevops)
- [**Wendell Dorta**](https://github.com/WendellD3v)

### Time Data Science ðŸ“Š
- [**AndrÃ© Ribeiro**](https://github.com/andrerochads)
- [**Kelly Muehlmann**](https://github.com/kellymuehlmann)
- [**Luiz Alves**](https://github.com/lf-all)
- [**Mariana Fernandes**](https://github.com/mari-martins-fernandes)

---

## ðŸ“ LicenÃ§a

Este projeto foi desenvolvido para o **Hackathon ONE (Oracle Next Education)** pela **Equipe DataBeats**.

---

## ðŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

---

## ðŸ“§ Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no [repositÃ³rio oficial](https://github.com/ezbueno/churninsight-api) ou entre em contato com a equipe.

---

**Desenvolvido com â¤ï¸ pela Equipe DataBeats | Hackathon ONE (Oracle Next Education)**
